/* Two-stage parallel reduction based on the "Simple Reductions" OpenCL
   optimization case study on the AMD Developer Central website */

/* The kernel should be called defining TYPE as the input/output data type,
   OP(acc, el) as the operator and OP_NULL as the null item for the operator
   (e.g. 0 for sum). Also, SMALL_WORKGROUP should be define if the worgroup
   size matches the device warp/wavefront size */

/* Two ways to do reductions are presented: one tries to do in-warp reductions
   first and then cross-warp reductions, the other follows a more traditional
   approach */

#ifndef TYPE
#define TYPE float
#endif

/* Token joiner for the C preprocessor */
#define _TOK(a, b) a##b
#define TOK(a, b) _TOK(a, b)

#ifndef FMIN_OP
#define FMIN_OP(acc, el) acc = fmin(acc, el)
#define FMIN_OP_NULL NAN
#endif

#ifndef ADD_OP
#define ADD_OP(acc, el) acc += el
#define ADD_OP_NULL 0
#endif

#if !defined(OP)
#error "Please define an OP"
#endif

#if !defined(OP_NULL)
#error "Please define an OP_NULL"
#endif

/* The VECSIZE is the vector width of the data type when reading from global memory.
   A VECSIZE of 1 means that each work-item reads elements one at a time, while
   e.g. a VECSIZE of 4 means that (if the datatype is int) each work-item reads
   an int4 at a time, while still reducing everythig to single ints. */

/* TODO: define VECREDUCE based on OP */
#if VECSIZE > 1
#define VECTYPE TOK(TYPE, VECSIZE)
#if OP != ADD_OP
#error "VECSIZE > 1 only supported for ADD_OP"
#endif
#if VECSIZE == 2
#define VECREDUCE(acc) acc.x + acc.y
#elif VECSIZE == 4
#define VECREDUCE(acc) acc.x + acc.y + acc.z + acc.w
#elif VECSIZE == 8
#define VECREDUCE(acc)	acc.s0 + acc.s1 + acc.s2 + acc.s3 + \
			acc.s4 + acc.s5 + acc.s6 + acc.s7
#elif VECSIZE == 16
#define VECREDUCE(acc)	acc.s0 + acc.s1 + acc.s2 + acc.s3 + \
			acc.s4 + acc.s5 + acc.s6 + acc.s7 + \
			acc.s8 + acc.s9 + acc.sa + acc.sb + \
			acc.sc + acc.sd + acc.se + acc.sf
#else
#error "Only vector sizes of 2, 4, 8 and 16 are supported"
#endif
#else
#define VECTYPE TYPE
#define VECREDUCE(acc) acc
#endif

/* The LOCAL_VECSIZE is the number of elements reduced in local memory
   by each active work-item. By default it's 2.
   The local work size should be a power of LOCAL_VECSIZE. */
#ifndef LOCAL_VECSIZE
#define LOCAL_VECSIZE 2
#endif

#if LOCAL_VECSIZE < 2
#error "LOCAL_VECSIZE should be at least 2"
#endif


__kernel void reduce(__global const VECTYPE* restrict input,
		__local volatile TYPE* restrict scratch,
		uint numels,
		__global TYPE* restrict output)
{
	/* Reduction may be done interleaved (style 0) or in blocks (style 1) */
#if REDUCTION_STYLE == 0
	/* Each work-item processes elements by jumping by the global size, until
	we run out */
	const uint end = numels;
	const uint stride = get_global_size(0);

	/* initialize */
	uint gid = get_global_id(0);
#elif REDUCTION_STYLE == 1
	/* Each group processes a block of consecutive elements. */

	/* The maximum number of elements to be processed by each group: */
	const uint els_per_group = (numels + get_num_groups(0) - 1)/get_num_groups(0);

	/* Within each block, the work-items proceed with a stride: */
	const uint stride = get_local_size(0);

	/* Range of elements */
	const uint begin = get_group_id(0)*els_per_group;
	const uint end = numels > begin + els_per_group ? begin + els_per_group : numels;

	/* initialize: */
	uint gid = begin + get_local_id(0);
#else
#error "Undefined REDUCTION_STYLE"
#endif

#if VECSIZE > 1
	VECTYPE vacc = (VECTYPE)(OP_NULL);
#endif
	TYPE acc = OP_NULL;

#if VECSIZE > 1 /* BEWARE: unprotected! */
#define REDUCE_1 OP(vacc, el); gid +=stride
#else
#define REDUCE_1 OP(acc, el); gid +=stride
#endif

#if UNROLL > 1
	while (gid < end && end - gid > UNROLL*stride) {
		VECTYPE el = input[gid];
		switch(UNROLL) {
		case 16: REDUCE_1; el = input[gid];
		case 15: REDUCE_1; el = input[gid];
		case 14: REDUCE_1; el = input[gid];
		case 13: REDUCE_1; el = input[gid];
		case 12: REDUCE_1; el = input[gid];
		case 11: REDUCE_1; el = input[gid];
		case 10: REDUCE_1; el = input[gid];
		case  9: REDUCE_1; el = input[gid];
		case  8: REDUCE_1; el = input[gid];
		case  7: REDUCE_1; el = input[gid];
		case  6: REDUCE_1; el = input[gid];
		case  5: REDUCE_1; el = input[gid];
		case  4: REDUCE_1; el = input[gid];
		case  3: REDUCE_1; el = input[gid];
		case  2: REDUCE_1; el = input[gid];
		}
		REDUCE_1;
	}
#endif

	while (gid < end) {
		VECTYPE el = input[gid];
		REDUCE_1;
	}

#if VECSIZE > 1
	acc = VECREDUCE(vacc);
#endif
	uint lid = get_local_id(0);
	scratch[lid] = acc;

#ifdef WAVE_SIZE
	/*  TODO support LOCAL_VECSIZE != 2 */
#if LOCAL_VECSIZE != 2
#warning "LOCAL_VECSIZE != 2 ignored"
#endif
	uint wave_num = lid / WAVE_SIZE;
	uint wid = lid - (wave_num * WAVE_SIZE);
	for (uint offset = WAVE_SIZE/2; offset; offset /= 2) {
		/* in-wave reductions don't need a barrier */
		//barrier(CLK_LOCAL_MEM_FENCE);
		if (wid < offset) {
			TYPE other = scratch[lid+offset];
			OP(acc, other);
			scratch[lid] = acc;
		}
	}
	/* cross-wave reductions */
	uint num_waves = (get_local_size(0) + WAVE_SIZE - 1)/WAVE_SIZE;
	for (uint skip_waves = 1; skip_waves < num_waves; skip_waves *=2) {
		barrier(CLK_LOCAL_MEM_FENCE);
		uint offset = skip_waves * WAVE_SIZE;
		if (wid == 0 && (wave_num & (2*skip_waves - 1)) == 0) {
			TYPE other = scratch[lid+offset];
			OP(acc, other);
			scratch[lid] = acc;
		}
	}
#else
	for (uint offset = get_local_size(0)/LOCAL_VECSIZE; offset; offset /= LOCAL_VECSIZE) {
#ifndef SMALL_WORKGROUP
		barrier(CLK_LOCAL_MEM_FENCE);
#endif
		if (lid < offset) {
			TYPE other = scratch[lid+offset];
			OP(acc, other);
#if LOCAL_VECSIZE > 2
#pragma unroll
			for (int next = 2; next < LOCAL_VECSIZE; ++next) {
				other = scratch[lid+next*offset];
				OP(acc, other);
			}
#endif
			scratch[lid] = acc;
		}
	}
#endif

	if (lid == 0)
		output[get_group_id(0)] = acc;
}
